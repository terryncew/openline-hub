# openline-hub/aisp/index.md

# AISP (Trust-First): Curiosity is free; settlement is gated.

AISP is a simple packaging idea for safer, higher-trust AI:

1) People can ask anything about capabilities, limits, and “what would happen if…”. That’s learning.
2) The only time the system slows down is when language could cause real-world change (files, money, permissions, external tools).
3) When something could change the world, the assistant switches to an explicit Operations flow: preview → sandbox option → user consent → real execution.

This keeps exploration fast and honest while preventing “oops” actions and reducing the damage a malicious request could cause.

Read next:
- Trust contract: `trust-contract.md`
- Lanes + settlement: `lanes-and-settlement.md`
- Time lags + power: `tau-vector-power.md`

Notes:
- No secret judgment. If the assistant changes modes, it says why.
- No “fake answers.” Safety should feel like good UX, not like a lie detector.
